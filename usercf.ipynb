{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使得随机数据可预测，即只要seed的值一样，后续生成的随机数都一样\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBasedCF(object):\n",
    "    ''' TopN recommendation - User Based Collaborative Filtering '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.trainset = {}\n",
    "        self.testset = {}\n",
    "\n",
    "        # n_sim_user: top 20个用户， n_rec_movie: top 10个推荐结果\n",
    "        self.n_sim_user = 20\n",
    "        self.n_rec_movie = 10\n",
    "\n",
    "        # user_sim_mat: 用户之间的相似度， movie_popular: 电影的出现次数， movie_count: 总电影数量\n",
    "        self.user_sim_mat = {}\n",
    "        self.movie_popular = {}\n",
    "        self.movie_count = 0\n",
    "\n",
    "        print ('Similar user number = %d' % self.n_sim_user, file=sys.stderr)\n",
    "        print ('recommended movie number = %d' % self.n_rec_movie, file=sys.stderr)\n",
    "\n",
    "    @staticmethod\n",
    "    def loadfile(filename):\n",
    "        ''' load a file, return a generator. '''\n",
    "        fp = open(filename, 'r')\n",
    "        for i, line in enumerate(fp):\n",
    "            yield line.strip('\\r\\n')\n",
    "            if i % 100000 == 0:\n",
    "                print ('loading %s(%s)' % (filename, i), file=sys.stderr)\n",
    "        fp.close()\n",
    "        print ('load %s succ' % filename, file=sys.stderr)\n",
    "\n",
    "    def generate_dataset(self, filename, pivot=0.7):\n",
    "        ''' load rating data and split it to training set and test set '''\n",
    "        trainset_len = 0\n",
    "        testset_len = 0\n",
    "\n",
    "        for line in self.loadfile(filename):\n",
    "            # 用户ID，电影名称，评分，时间戳\n",
    "            user, movie, rating, _ = line.split('::')\n",
    "            # split the data by pivot\n",
    "            if random.random() < pivot:\n",
    "                self.trainset.setdefault(user, {})\n",
    "                self.trainset[user][movie] = int(rating)\n",
    "                trainset_len += 1\n",
    "            else:\n",
    "                self.testset.setdefault(user, {})\n",
    "                self.testset[user][movie] = int(rating)\n",
    "                testset_len += 1\n",
    "\n",
    "        print ('split training set and test set succ', file=sys.stderr)\n",
    "        print ('train set = %s' % trainset_len, file=sys.stderr)\n",
    "        print ('test set = %s' % testset_len, file=sys.stderr)\n",
    "\n",
    "    def calc_user_sim(self):\n",
    "        ''' calculate user similarity matrix '''\n",
    "        # build inverse table for item-users\n",
    "        # key=movieID, value=list of userIDs who have seen this movie\n",
    "        print ('building movie-users inverse table...', file=sys.stderr)\n",
    "        movie2users = dict()\n",
    "\n",
    "        for user, movies in self.trainset.items():\n",
    "            for movie in movies:\n",
    "                # inverse table for item-users\n",
    "                if movie not in movie2users:\n",
    "                    movie2users[movie] = set()\n",
    "                movie2users[movie].add(user)\n",
    "                # count item popularity at the same time\n",
    "                if movie not in self.movie_popular:\n",
    "                    self.movie_popular[movie] = 0\n",
    "                self.movie_popular[movie] += 1\n",
    "        print ('build movie-users inverse table succ', file=sys.stderr)\n",
    "\n",
    "        # save the total movie number, which will be used in evaluation\n",
    "        self.movie_count = len(movie2users)\n",
    "        print ('total movie number = %d' % self.movie_count, file=sys.stderr)\n",
    "\n",
    "        # count co-rated items between users\n",
    "        usersim_mat = self.user_sim_mat\n",
    "        print ('building user co-rated movies matrix...', file=sys.stderr)\n",
    "\n",
    "        for movie, users in movie2users.items():\n",
    "            for u in users:\n",
    "                usersim_mat.setdefault(u, defaultdict(int))\n",
    "                for v in users:\n",
    "                    if u == v:\n",
    "                        continue\n",
    "                    usersim_mat[u][v] += 1\n",
    "        print ('build user co-rated movies matrix succ', file=sys.stderr)\n",
    "\n",
    "        # calculate similarity matrix\n",
    "        print ('calculating user similarity matrix...', file=sys.stderr)\n",
    "        simfactor_count = 0\n",
    "        PRINT_STEP = 2000000\n",
    "\n",
    "        for u, related_users in usersim_mat.items():\n",
    "            for v, count in related_users.items():\n",
    "                # 余弦相似度\n",
    "                usersim_mat[u][v] = count / math.sqrt(\n",
    "                    len(self.trainset[u]) * len(self.trainset[v]))\n",
    "                simfactor_count += 1\n",
    "                # 打印进度条\n",
    "                if simfactor_count % PRINT_STEP == 0:\n",
    "                    print ('calculating user similarity factor(%d)' %\n",
    "                           simfactor_count, file=sys.stderr)\n",
    "\n",
    "        print ('calculate user similarity matrix(similarity factor) succ',\n",
    "               file=sys.stderr)\n",
    "        print ('Total similarity factor number = %d' %\n",
    "               simfactor_count, file=sys.stderr)\n",
    "\n",
    "    def recommend(self, user):\n",
    "        ''' Find K similar users and recommend N movies. '''\n",
    "        K = self.n_sim_user\n",
    "        N = self.n_rec_movie\n",
    "        rank = dict()\n",
    "        watched_movies = self.trainset[user]\n",
    "\n",
    "        # 计算top K 用户的相似度\n",
    "        # v=similar user, wuv=不同用户同时出现的次数，根据wuv倒序从大到小选出K个用户进行排列\n",
    "        # 耗时分析：50.4%的时间在 line-160行\n",
    "        for similar_user, similarity_factor in sorted(self.user_sim_mat[user].items(),\n",
    "                                                      key=itemgetter(1), reverse=True)[0:K]:\n",
    "            for movie in self.trainset[similar_user]:\n",
    "                if movie in watched_movies:\n",
    "                    continue\n",
    "                # predict the user's \"interest\" for each movie\n",
    "                rank.setdefault(movie, 0)\n",
    "                rank[movie] += similarity_factor\n",
    "        # return the N best movies\n",
    "        return sorted(rank.items(), key=itemgetter(1), reverse=True)[0:N]\n",
    "\n",
    "    def evaluate(self):\n",
    "        ''' print evaluation result: precision, recall, coverage and popularity '''\n",
    "        print ('Evaluation start...', file=sys.stderr)\n",
    "\n",
    "        N = self.n_rec_movie\n",
    "        #  varables for precision and recall\n",
    "        hit = 0  # hit 命中(测试集和推荐集相同+1)\n",
    "        rec_count = 0  # rec_count 每个用户的推荐数\n",
    "        test_count = 0  # est_count 每个用户对应的测试数据集的电影数\n",
    "        # varables for coverage\n",
    "        all_rec_movies = set()\n",
    "        # varables for popularity\n",
    "        popular_sum = 0\n",
    "\n",
    "        for i, user in enumerate(self.trainset):\n",
    "            if i % 500 == 0:\n",
    "                print ('recommended for %d users' % i, file=sys.stderr)\n",
    "            test_movies = self.testset.get(user, {})\n",
    "            rec_movies = self.recommend(user)\n",
    "            # 对比测试集和推荐集的差异\n",
    "            for movie, _ in rec_movies:\n",
    "                if movie in test_movies:\n",
    "                    hit += 1\n",
    "                all_rec_movies.add(movie)\n",
    "                popular_sum += math.log(1 + self.movie_popular[movie])\n",
    "            rec_count += N\n",
    "            test_count += len(test_movies)\n",
    "\n",
    "        precision = hit / (1.0 * rec_count)\n",
    "        recall = hit / (1.0 * test_count)\n",
    "        coverage = len(all_rec_movies) / (1.0 * self.movie_count)\n",
    "        popularity = popular_sum / (1.0 * rec_count)\n",
    "\n",
    "        print ('precision=%.4f\\trecall=%.4f\\tcoverage=%.4f\\tpopularity=%.4f' %\n",
    "               (precision, recall, coverage, popularity), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Similar movie number = 20\n",
      "Recommended movie number = 10\n",
      "loading ml-1m\\ratings.dat(0)\n",
      "loading ml-1m\\ratings.dat(100000)\n",
      "loading ml-1m\\ratings.dat(200000)\n",
      "loading ml-1m\\ratings.dat(300000)\n",
      "loading ml-1m\\ratings.dat(400000)\n",
      "loading ml-1m\\ratings.dat(500000)\n",
      "loading ml-1m\\ratings.dat(600000)\n",
      "loading ml-1m\\ratings.dat(700000)\n",
      "loading ml-1m\\ratings.dat(800000)\n",
      "loading ml-1m\\ratings.dat(900000)\n",
      "loading ml-1m\\ratings.dat(1000000)\n",
      "load ml-1m\\ratings.dat succ\n",
      "split training set and test set succ\n",
      "train set = 699977\n",
      "test set = 300232\n",
      "counting movies number and popularity...\n",
      "count movies number and popularity succ\n",
      "total movie number = 3658\n",
      "building co-rated users matrix...\n",
      "build co-rated users matrix succ\n",
      "calculating movie similarity matrix...\n",
      "calculating movie similarity factor(2000000)\n",
      "calculating movie similarity factor(4000000)\n",
      "calculating movie similarity factor(6000000)\n",
      "calculating movie similarity factor(8000000)\n",
      "calculating movie similarity factor(10000000)\n",
      "calculate movie similarity matrix(similarity factor) succ\n",
      "Total similarity factor number = 10137306\n",
      "Evaluation start...\n",
      "recommended for 0 users\n",
      "recommended for 500 users\n",
      "recommended for 1000 users\n",
      "recommended for 1500 users\n",
      "recommended for 2000 users\n",
      "recommended for 2500 users\n",
      "recommended for 3000 users\n",
      "recommended for 3500 users\n",
      "recommended for 4000 users\n",
      "recommended for 4500 users\n",
      "recommended for 5000 users\n",
      "recommended for 5500 users\n",
      "recommended for 6000 users\n",
      "precision=0.3798\trecall=0.0764\tcoverage=0.1689\tpopularity=7.1600\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # 创建UserCF对象\n",
    "    usercf = UserBasedCF()\n",
    "    \n",
    "    # 将数据按照 7:3的比例，拆分成：训练集和测试集，存储在usercf的trainset和testset中\n",
    "    ratingfile = os.path.join('ml-1m', 'ratings.dat')\n",
    "    usercf.generate_dataset(ratingfile)\n",
    "    \n",
    "    # 计算用户之间的相似度\n",
    "    usercf.calc_user_sim()\n",
    "    \n",
    "    # 评估推荐效果\n",
    "    usercf.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看某用户推荐结果\n",
    "user = \"2\"\n",
    "print(\"推荐结果\", itemcf.recommend(user))\n",
    "print(\"---\", itemcf.testset.get(user, {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'661': 3, '914': 3, '3408': 4, '2355': 5, '1197': 3, '594': 4, '919': 4, '938': 4, '2398': 4, '2918': 4, '1035': 5, '2018': 4, '3105': 5, '1270': 5, '527': 5, '48': 5, '1097': 4, '1721': 4, '1545': 4, '745': 3, '3186': 4, '1566': 4, '588': 4, '1907': 4, '783': 4, '1836': 5, '1022': 5, '2762': 4, '150': 5, '1961': 5, '1962': 4, '2692': 4, '1029': 5, '1207': 4, '531': 4, '3114': 4, '608': 4, '1246': 4}\n",
      "2 {'1357': 5, '3068': 4, '1537': 4, '2268': 5, '2628': 3, '1103': 3, '1210': 4, '1792': 3, '1687': 3, '1213': 2, '2881': 3, '3105': 4, '434': 2, '2126': 3, '3035': 4, '292': 3, '2236': 5, '3071': 4, '902': 2, '368': 4, '1259': 5, '3147': 5, '1544': 4, '1293': 5, '1188': 4, '3256': 2, '3257': 3, '2278': 3, '2490': 3, '3654': 3, '2852': 3, '1945': 5, '982': 4, '1873': 4, '2858': 4, '1225': 5, '442': 3, '265': 4, '1408': 3, '1084': 3, '3699': 2, '480': 5, '1442': 4, '1265': 3, '1193': 5, '2353': 4, '3334': 4, '2427': 2, '590': 5, '1196': 5, '1552': 3, '736': 4, '593': 5, '2359': 3, '95': 2, '1917': 3, '2396': 4, '3735': 3, '1953': 4, '3809': 3, '1954': 5, '1955': 4, '1124': 5, '1957': 5, '21': 1, '2321': 3, '1090': 2, '380': 5, '2501': 5, '920': 5, '459': 3, '3418': 4, '1385': 3, '3451': 4, '2728': 3, '1962': 5, '1784': 5, '318': 5, '1207': 4, '1968': 2, '3678': 3, '356': 5, '1246': 5}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for key,values in itemcf.trainset.items():\n",
    "    if i<2: print(key,values)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
